251*128/311
251*183/311
expected <- c(24.7, 35.3, 103.3, 147.7)
observed <- c(26, 34, 102, 149)
c <- sum((observed-expected)^2/expected)
c
39+54
25+16
expected <- c(24.7, 35.3, 103.3, 147.7)
observed <- c(26, 34, 102, 149)
c <- sum((observed-expected)^2/expected)
c
1-pchisq(c, df=1)
expected <- c(72.67, 103.33, 38.4, 54.6, 16.93, 24.071)
observed <- c(64, 112, 39, 54, 25, 16)
c <- sum((observed-expected)^2/expected)
c
1-pchisq(c, df=1)
expected <- c(39.1, 55.9, 88.9, 127.1)
observed <- c(48, 47, 80, 136)
c <- sum((observed-expected)^2/expected)
c
expected <- c(80.713, 84.287, 74.3538, 77.64621, 41.5794,
43.421, 32.7744, 34.2256, 41.5794, 43.421)
observed <- c(95, 70, 52, 100, 52, 33, 35, 32, 37, 48)
c <- sum((observed-expected)^2/expected)
c
1-pchisq(c, df=1)
expected <- c(72.67, 103.33, 38.4, 54.6, 16.93, 24.071)
observed <- c(64, 112, 39, 54, 25, 16)
c <- sum((observed-expected)^2/expected)
c
1-pchisq(c, df=2)
expected <- c(70.791, 101.21, 57.21, 81.791)
observed <- c(78, 94, 50, 89)
c <- sum((observed-expected)^2/expected)
c
1-pchisq(c, df=1)
expected <- c(20.579, 29.421, 107.421, 153.5788)
observed <- c(13, 37, 115, 146)
c <- sum((observed-expected)^2/expected)
c
1-pchisq(c, df=1)
28+37
88+128
216+30+65
expected <- c(88.9, 127.1, 26.75, 38.25, 12.35, 17.65)
observed <- c(88, 128, 28, 37, 12, 18)
c <- sum((observed-expected)^2/expected)
c
pred1 <- readRDS("~/Google Drive/Stanford/Stanford Y2 Q1/CS 221/CS221FinalProject/Predictions/predictions_7_107.rds")
View(pred1)
pred2 <- readRDS("~/Google Drive/Stanford/Stanford Y2 Q1/CS 221/CS221FinalProject/Predictions/predictions_108_357.rds")
pred3 <- readRDS("~/Google Drive/Stanford/Stanford Y2 Q1/CS 221/CS221FinalProject/Predictions/predictions_358_507.rds")
pred4 <- readRDS("~/Google Drive/Stanford/Stanford Y2 Q1/CS 221/CS221FinalProject/Predictions/predictions_508_1007.rds")
a <- c(1,1,0,0)
b <- c(0,1,0,1)
bitwAnd(a,b)
prediction <- pred3
n = nrow(prediction)
m = ncol(prediction)
m1 = rep(0, n)
m1_test = rep(0, n)
thisObsKeywords = test[i, 6:nrow(test)]
library(data.table)
library(caTools)
## Read in the big data set however necessary.
#data = data.table(read.csv("~/Downloads/dataset.csv"), sep = ',', header = FALSE, fill = TRUE)
#saveRDS(data, "~/Documents/cs221/CS221FinalProject/data.rds")
data = readRDS("~/Google Drive/Stanford/Stanford Y2 Q1/CS 221/CS221FinalProject/data.rds")
data_ = subset(data, select=c(2,4,5,6,7,8,9,10,11,12:ncol(data)))
colnames(data_)
# 2/3 of observations dont have a region 2
data_$region_2 = NULL
# 1/3 of observations dont have a designation
data_$designation = NULL
# Basically one winery per row... not predictive
data_$winery = NULL
# Lots of blanks, remove rows with blank cells
data_[data_==""] = NA
data_s = na.omit(data_)
# Grab the most frequent categories
countries = tail(names(sort(table(data_s$country))), 15)
provinces = tail(names(sort(table(data_s$province))), 50)
regions = tail(names(sort(table(data_s$region_1))), 50)
varieties = tail(names(sort(table(data_s$variety))), 100)
# wineries = tail(names(sort(table(data_s$winery))), 1500)
data_s = data_s[country %in% countries & province %in% provinces & region_1 %in% regions & variety %in% varieties,]
# sample = sample.int(n = nrow(data_s), size = floor(.8*nrow(data_s)), replace = F)
# train = data[sample, ]
# test  = data[-sample, ]
set.seed(1)
split = sample.split(data_s$flavors, SplitRatio = 0.8)
train = subset(data_s, split == TRUE)
test = subset(data_s, split == FALSE)
prediction <- pred3
n = nrow(prediction)
m = ncol(prediction)
m1 = rep(0, n)
m1_test = rep(0, n)
i=1
in_review = 0
in_prediction = 0
thisObsKeywords = test[i, 6:nrow(test)]
thisObsKeywords = test[i, 7:nrow(test)]
thisObsKeywords = test[i, 7:(m+6)]
thisObsKeywords
names(test)
startIndex <- 358
thisObsKeywords = test[i, startIndex:(m+startIndex)]
thisObsKeywords
names(prediction)
thisObsKeywords = test[i, startIndex:(m+startIndex+1)]
names(thisObsKeywords)
thisObsKeywords = test[i, startIndex:(m+startIndex)]
names(thisObsKeywords)
names(prediction)
thisObsKeywords = test[i, startIndex:(m+startIndex+1)]
names(prediction)
names(thisObsKeywords)
thisObsKeywords = test[i, startIndex:(m+startIndex)]
names(thisObsKeywords)
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
names(thisObsKeywords)
round(prediction[i, startIndex:(m+startIndex-1)]+0.25)
prediction[i, startIndex:(m+startIndex-1)]
in_review = sum(thisObsKeywords)
in_review
thisObsKeywords
prediction[i, startIndex:(m+startIndex-1)]
startIndex
prediction
prediction[i, 1:m]
prediction[i, 1:m]+0.25
round(prediction[i, 1:m]+0.25)
in_prediction = bitwAnd(thisObsKeywords, predictions)
predictions <- round(prediction[i, 1:m]+0.25)
in_review = sum(thisObsKeywords)
in_prediction = bitwAnd(thisObsKeywords, predictions)
thisObsKeywords
predictions
typeof(thisObsKeywords)
typeof(as.vector(thisObsKeywords))
typeof(as.numeric(thisObsKeywords))
as.numeric(thisObsKeywords)
in_prediction = bitwAnd(as.numeric(thisObsKeywords), as.numeric(predictions))
in_prediction
prediction <- pred3
n = nrow(prediction)
m = ncol(prediction)
startIndex <- 358
m1 = rep(0, n)
m1_test = rep(0, n)
for (i in 1:n) {
in_review = 0
in_prediction = 0
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
predictions <- round(prediction[i, 1:m]+0.25)
in_review = sum(thisObsKeywords)
in_prediction = bitwAnd(as.numeric(thisObsKeywords), as.numeric(predictions))
m1_test[i] = in_prediction / in_review
}
for (i in 1:n) {
print(i)
in_review = 0
in_prediction = 0
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
predictions <- round(prediction[i, 1:m]+0.25)
in_review = sum(thisObsKeywords)
in_prediction = bitwAnd(as.numeric(thisObsKeywords), as.numeric(predictions))
m1_test[i] = in_prediction / in_review
}
m1_test[is.nan(m1)]=NA
mean(m1_test, na.rm = TRUE)
i=2
in_review = 0
in_prediction = 0
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
predictions <- round(prediction[i, 1:m]+0.25)
thisObsKeywords
i=3
thisObsKeywords
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
thisObsKeywords
predictions <- round(prediction[i, 1:m]+0.25)
predictions
prediction <- pred4
n = nrow(prediction)
m = ncol(prediction)
startIndex <- 508
m1 = rep(0, n)
m1_test = rep(0, n)
print(i)
in_review = 0
in_prediction = 0
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
thisObsKeywords
in_review = sum(thisObsKeywords)
predictions <- round(prediction[i, 1:m]+0.25)
in_prediction = bitwAnd(as.numeric(thisObsKeywords), as.numeric(predictions))
in_prediction = sum(bitwAnd(as.numeric(thisObsKeywords), as.numeric(predictions)))
m1_test[i] = in_prediction / in_review
m1_test[i]
prediction <- pred4
n = nrow(prediction)
m = ncol(prediction)
startIndex <- 508
m1 = rep(0, n)
m1_test = rep(0, n)
for (i in 1:100) {
print(i)
in_review = 0
in_prediction = 0
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
predictions <- round(prediction[i, 1:m]+0.25)
in_review = sum(thisObsKeywords)
in_prediction = sum(bitwAnd(as.numeric(thisObsKeywords), as.numeric(predictions)))
m1_test[i] = in_prediction / in_review
}
m1_test[is.nan(m1)]=NA
mean(m1_test, na.rm = TRUE)
predictions <- round(prediction[i, 1:m]+0.25)
thisObsKeywords = test[i, startIndex:(m+startIndex-1)]
predictions-thisObsKeywords
predictions
as.numeric(predictions)-as.numeric(thisObsKeywords)
table(as.numeric(predictions)-as.numeric(thisObsKeywords))
table(as.numeric(predictions)-as.numeric(thisObsKeywords))["1"]
as.numeric(table(as.numeric(predictions)-as.numeric(thisObsKeywords))["1"])
not_in_review / in_prediction
not_in_review = as.numeric(table(as.numeric(predictions)-as.numeric(thisObsKeywords))["1"])
in_prediction = sum(predictions)
not_in_review / in_prediction
# This code opens the several linear regression results produced earlier
# And combine them in a way that can be easily written to LaTeX
rm(list = ls())
library(xtable)
library(dplyr)
library(ggplot2)
library(reshape)
library(GGally)
library(MuMIn)
setwd("~/Google Drive/EliteLaw/Generate Latex/")
# Open files
load('RegressionsResults.RData')
load('../Data/EliteLawDf2016.RData')
source('GenerateLatex.R')
source('../Analysis/ModelAveraging.R')
source('../Analysis/InterpretPValueSummary.R')
source('../Analysis/CoefficientsByYear.R')
################################################################
###################### Summary Statistics ######################
summaryTables <- GenerateSummaryStatistics(df)
alignment <- paste(c("l",rep("r",ncol(summaryTables))), collapse="")
print(xtable(summaryTables, align=alignment), hline.after=c(-1,0, 6, 12, 18, 24, nrow(summaryTables)),
file="IndivTexOutput/summary.tex", sanitize.text.function=function(x){x})
aggVariableSummaryTable <- GenerateAggVarSummary(df)
print(xtable(aggVariableSummaryTable), file="IndivTexOutput/summaryaggvars.tex", sanitize.text.function=function(x){x})
################################################################
################################################################
###################### Correlations ############################
# # get the correlations table
corDF <- GenerateCorrelations(df)
print(xtable(corDF, digits=3), file="IndivTexOutput/corrTable.tex")
# prints the correlation table by rank
corByRank <- GenerateCorrelationsByRank(df)
correlationsByRank <- corByRank[[1]]
print(xtable(correlationsByRank, digits=3), file="IndivTexOutput/MnAGDP.tex")
# now make the 6 graphs with correlations
correlRanks <- corByRank[[2]]
#SaveCorrelationsByRankPlots(df, correlRanks)
################################################################
################################################################
###################### Regression Tables #######################
# Build all of the regression tables and save them in an organized fashion.
tables <- GenerateRegressionTables(resultsCoeffs,resultsTValues, resultsPValues)
# save all of the latex tables to files
for (i in 1:length(tables)) {
istr = as.character(i)
if (i < 10) {
istr = paste("0",i,sep="")
}
fileName <- paste("IndivTexOutput/regressions-table",istr,".tex",sep="")
print(tables[[i]], file=fileName, sanitize.text.function=function(x){x})
}
# Build the appropriate dataframes by slicing from the correct columns
#Performance.Rev.Lawyer.With.Lawyers = resultsPerformance[, 1:9] # unused
# Generate the Performance Table
GeneratePerformanceTable(resultsPerformance)
# Generate and save the summary table for the p-values
table <- GeneratePValueSummaryTable(resultsPValues, yearPValues, firmPValues)
alignment <- paste(c("l",rep("c",ncol(table))), collapse="")
caption <- paste("Percentage of regressions in which each variable is significant at, and in how many the variable appears.\\\\Total number of regressions: ",
max(table[1:(nrow(table)-2),ncol(table)]), ".", sep="")
print(xtable(table,digits=0, align=alignment, caption=caption),
file="IndivTexOutput/pvaltable.tex", sanitize.text.function=function(x){x})
# Create the temp table from InterpretPValueSummary
# This table helps identify trends in where the p-values are not significant.
createAndSaveTempTable(df, resultsCoeffs, resultsPValues)
################################################################
################################################################
#################### Regressions by Year #######################
# This function will generate the table that, given the regression of choice,
# will include the coefficients of all variables in the model for a specific year.
# Note that it would not make sense to include any fixed effects in this model.
buildAndSaveCoefficientsByYear(df)
################################################################
################################################################
####################### Model Averaging ########################
# save the model averaging to the tables
saveModelAveraging(df)
################################################################
####################################################################################
############################ UNUSED CORRELATION PLOTS ##############################
####################################################################################
#
# # save the correlation heatmap
# heatmap <- ggplot(data = melt(corDF), aes(x=X1, y=X2, fill=value)) + geom_tile() +
#   xlab("") + ylab("") + ggtitle("Correlations HeatMap") +
#   labs(fill='Correlation')
# ggsave(file="IndivTexOutput/corrHeatmap.jpg", heatmap, width=8, height=5, dpi=300)
#
# # the ggpairs plot
# # Function to perform multiple plots with regressions
# ggpairs_with_linreg <- function(data, mapping, ...){
#   p <- ggplot(data = data, mapping = mapping) +
#     geom_point() +
#     geom_smooth(method=lm, fill="blue", color="red", ...)
#   return(p)
# }
#
#
#
# toPlot <- df[, c("Lawyers", "Leverage", "GrossRev", "NOI", "IPORevenue", "EquityRevenue",
#                  "MnARevenue", "GrossRev.Lawyer", "NOI.Lawyer", "NOI.eqPart")]
#
# labels <- names(toPlot)
# labels <- gsub("GrossRev", "Rev", labels)
# labels <- gsub(".eqPart", "/EqPart", labels)
# labels <- gsub(".Lawyer", "/Law", labels)
# labels <- gsub("Revenue", "", labels)
# labels <- gsub("MnA", "M&A", labels)
#
#
# graph <- ggpairs(toPlot, lower = list(continuous = ggpairs_with_linreg),
#       columnLabels=labels)
# ggsave(file="IndivTexOutput/corrGGpairs.jpg", graph, width=8, height=5, dpi=300)
##################################################################
# Clear environment
#rm(list = ls())
# Load libraries
library(dplyr)
library(lm.beta)
library(xtable)
library(corrplot)
# Load dataframe
setwd("~/Google Drive/EliteLaw/Generate Latex/")
load('../Data/EliteLawDf2016.RData')
#load('Data/EliteLawDf.RData')
computePairwiseDifferencesZtestPVal <- function(coefbyyear, variable, years) {
MnARevcomparisons <- c()
MnARev <- as.numeric(coefbyyear[variable,])
MnARev2016 <- as.numeric(coefbyyear[variable,"2016"])
denom <- sd(MnARev)/sqrt(length(MnARev))
for (year in years) {
if (year == 2016) {
MnARevcomparisons <- c(MnARevcomparisons, NA)
next;
}
thisMnARev <- as.numeric(coefbyyear[variable,as.character(year)])
zval <- abs((thisMnARev - MnARev2016)/denom)
pval <- 1-pnorm(zval)
if (pval < 0.001) {
pval <- "\\textless 0.001"
} else {
pval <- prettyNum(pval, digits=3, mode="double", width=3)
}
MnARevcomparisons <- c(MnARevcomparisons, pval)
}
return(MnARevcomparisons)
}
computePairwiseDifferencesPVal <- function(df, years) {
comparisonsRevenue <- c()
comparisonsIssues <- c()
for (year in years) {
if (year == 2016) {
comparisonsRevenue <- c(comparisonsRevenue, NA)
comparisonsIssues <- c(comparisonsIssues, NA)
next;
}
thisDF <- df %>% filter(Year %in% c(year, 2016))
modelRevenue <- lm(GrossRev ~ Lawyers + Leverage +
MnARevenue + EquityRevenue + IPORevenue +
MnANumOfDeals + EquityIssues + IPOIssues + MnARevenue*Year, data=thisDF)
pvalRevenue <- summary(modelRevenue)$coefficients["MnARevenue:Year",4]
if (pvalRevenue < 0.001) {
pvalRevenue <- "\\textless 0.001"
} else {
pvalRevenue <- prettyNum(pvalRevenue, digits=3, mode="double", width=1)
}
comparisonsRevenue <- c(comparisonsRevenue, pvalRevenue)
modelIssues <- lm(GrossRev ~ Lawyers + Leverage +
MnARevenue + EquityRevenue + IPORevenue +
MnANumOfDeals + EquityIssues + IPOIssues + MnANumOfDeals*Year, data=thisDF)
pvalIssues <- summary(modelIssues)$coefficients["MnANumOfDeals:Year",4]
if (pvalIssues < 0.001) {
pvalIssues <- "\\textless 0.001"
} else {
pvalIssues <- prettyNum(pvalIssues, digits=3, mode="double", width=1)
}
comparisonsIssues <- c(comparisonsIssues, pvalIssues)
}
return(rbind(comparisonsRevenue, comparisonsIssues))
}
# -------------------------------------------------------------------------------------------------
# Current Analysis
# -------------------------------------------------------------------------------------------------
buildAndSaveCoefficientsByYear <- function(df) {
print("Building Table for Coefficients by Year")
years <- sort(unique(as.numeric(df$Year)), decreasing=TRUE)
covariates = c("(Intercept)", "Lawyers", "Leverage",
"MnARevenue", "EquityRevenue", "IPORevenue",
"MnANumOfDeals", "EquityIssues", "IPOIssues")
coefbyyear <- data.frame(matrix(ncol=length(years), nrow=(length(covariates)+1)))
names(coefbyyear) <- years
row.names(coefbyyear) <- c(covariates, "metric\\tablefootnote[3]{Mean of the p-values of the interaction terms ($covariate_i*year$), where year=(2016 or X). Data includes year X and 2016.}")
preciseTable <- data.frame(matrix(ncol=length(years), nrow=length(covariates)))
names(preciseTable) <- years
row.names(preciseTable) <- c(covariates)
for (year in years) {
#thisDF <- df %>% filter(Year == year)
thisDF <- df %>% filter(Year %in% c(year, 2016))
# defines them exactly
model5 <- lm(GrossRev ~ Lawyers + Leverage +
MnARevenue + EquityRevenue + IPORevenue +
MnANumOfDeals + EquityIssues + IPOIssues, data=thisDF)
coefficients <- coef(model5)
coefbyyear[1:length(covariates),as.character(year)] <- prettyNum(coefficients, digits=3, mode="double", width=1)
preciseTable[1:length(covariates),as.character(year)] <- coefficients
if (year != 2016) {
interactionPValues <- c()
for (variable in covariates[2:length(covariates)]) {
formula <- as.formula(paste(c("GrossRev ~", paste(covariates[2:length(covariates)], collapse=" + "), paste("+ ", variable, "*Year", sep="")), collapse=" "))
model5interaction <- lm(formula, data=thisDF)
whichInteraction <- grepl(":", names(summary(model5interaction)$coefficients[,4]))
interactionpval <- summary(model5interaction)$coefficients[whichInteraction,4]
interactionPValues <- c(interactionPValues, interactionpval)
}
# model5interaction <- lm(GrossRev ~ Lawyers + Leverage +
#                           MnARevenue + EquityRevenue + IPORevenue +
#                           MnANumOfDeals + EquityIssues + IPOIssues, data=thisDF)
#
# whichInteraction <- grepl(":", names(summary(model5interaction)$coefficients[,4]))
# interactionPValues <- summary(model5interaction)$coefficients[whichInteraction,4]
coefbyyear[nrow(coefbyyear),as.character(year)] <- prettyNum(mean(interactionPValues), digits=3, mode="double", width=1)
# add the t-statistic column to see if there are significant differences
#pval <- t.test(as.numeric(preciseTable[2:length(covariates),"2016"]), coefficients[2:length(coefficients)], paired=TRUE)$p.value
#coefbyyear[nrow(coefbyyear),as.character(year)] <- prettyNum(pval, digits=3, mode="double", width=1)
}
}
# remove the intercept column
#coefbyyear <- coefbyyear[-1,]
#corrplot(cor(preciseTable), method = "color")
newRows <- computePairwiseDifferencesPVal(df, years)
coefbyyear <- rbind(coefbyyear, newRows[1,])
coefbyyear <- rbind(coefbyyear, newRows[2,])
row.names(coefbyyear)[(nrow(coefbyyear)-1):nrow(coefbyyear)] <- c("metric\\tablefootnote[4]{MnA Deal Value coefficient of year X vs. MnA Deal Value coefficient of 2016 (p-value)}",
"metric\\tablefootnote[5]{MnA Transactions coefficient of year X vs. MnA Transactions coefficient of 2016 (p-value)}")
row.names(coefbyyear) <- gsub("MnARevenue", " MnA D.V.\\\\tablefootnote[1]{D.V. = Deal Value}", row.names(coefbyyear))
row.names(coefbyyear) <- gsub("MnAIssues", " MnA T.\\\\tablefootnote[2]{T. = Transactions}", row.names(coefbyyear))
row.names(coefbyyear) <- gsub("MnANumOfDeals", " MnA T.\\\\tablefootnote[2]{T. = Transactions}", row.names(coefbyyear))
row.names(coefbyyear) <- gsub("Revenue", " D.V.", row.names(coefbyyear))
row.names(coefbyyear) <- gsub("Issues", " T.", row.names(coefbyyear))
captionText <- "The entries in this table are coefficients for regression \\#5, per year.
We have 9+3 columns - one for each coefficient that is in the model and 3 more described in footnotes.
Agg MnA, Agg Equity, Agg IPO, and GDP are excluded since the regressions are for one year and those
variables are fixed for a given year."
print(xtable(t(coefbyyear), digits=3, caption=captionText),
file="IndivTexOutput/coefbyyear.tex",
NA.string = getOption("xtable.NA.string", "NA"),
sanitize.text.function=function(x){x})
print("Done!")
return(coefbyyear)
}
#View(buildAndSaveCoefficientsByYear(df))
buildAndSaveCoefficientsByYear(df)
View(df)
# This code opens the several linear regression results produced earlier
# And combine them in a way that can be easily written to LaTeX
rm(list = ls())
library(xtable)
library(dplyr)
library(ggplot2)
library(reshape)
library(GGally)
library(MuMIn)
setwd("~/Google Drive/EliteLaw/Generate Latex/")
# Open files
load('RegressionsResults.RData')
load('../Data/EliteLawDf2016.RData')
source('GenerateLatex.R')
source('../Analysis/ModelAveraging.R')
source('../Analysis/InterpretPValueSummary.R')
source('../Analysis/CoefficientsByYear.R')
################################################################
###################### Summary Statistics ######################
summaryTables <- GenerateSummaryStatistics(df)
alignment <- paste(c("l",rep("r",ncol(summaryTables))), collapse="")
print(xtable(summaryTables, align=alignment), hline.after=c(-1,0, 7, 13, 19, 25, nrow(summaryTables)),
file="IndivTexOutput/summary.tex", sanitize.text.function=function(x){x})
aggVariableSummaryTable <- GenerateAggVarSummary(df)
print(xtable(aggVariableSummaryTable), file="IndivTexOutput/summaryaggvars.tex", sanitize.text.function=function(x){x})
